{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with these two lines of code and with using streamlit web framework\n",
    "#we can set up a web server with a web page that will say hello world\n",
    "import streamlit as st##\n",
    "st.title('Hello, world!')##\n",
    "\n",
    "#then in command prompt: streamlit run app.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the title\n",
    "st.title('My Chatbot UI')##\n",
    "#container will contain the text box & a button that we can use to send our message\n",
    "container = st.container()##\n",
    "\n",
    "#in order to fill in the stuff that we want in the container we say\n",
    "with container:##\n",
    "    #then we create a form we just call it something we give it an identifier in this case just my form \n",
    "    with st.form(key=\"my_form\", clear_on_submit=True):###clear_on_submit=True is once we type in our text and click the submit button uh the text will clear out\n",
    "        user_input = st.text_area(\"You\", key=\"input\", height=100)##\n",
    "        submit_button=st.form_submit_button(label=\"Send\")##\n",
    "\n",
    "    if submit_button and user_input:##\n",
    "        st.write(f\"Hello {user_input}\") ###rerun on the webpage no.2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of just replying with hello and user input we actually want now to call the \n",
    "\n",
    "#create a function in order to um create the responses \n",
    "def generate_response(prompt):\n",
    "\n",
    "\n",
    "    if submit_button and user_input:\n",
    "        output= generate_response(user_input)##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the open AI API in order to get a response from GPT \n",
    "# search in google:openAI chat completion Introduction\n",
    "import openai ##\n",
    "\n",
    "openai.api_key=open(\"key.txt\",\"r\").read().strip('\\n') ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from https://platform.openai.com/docs/guides/chat/introduction\n",
    "def generate_response(prompt):\n",
    "    openai.ChatCompletion.create(##\n",
    "  model=\"gpt-3.5-turbo\",##\n",
    "  messages=[##\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},##\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},##\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}##\n",
    "    ]##\n",
    ")##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove last two role. make user role content prompt\n",
    "def generate_response(prompt):\n",
    "    openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},##\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to capture the output \n",
    "#copy assistant's reply from https://platform.openai.com/docs/guides/chat/introduction\n",
    "#create return variable and return response by copying   response['choices'][0]['message']['content']   from https://platform.openai.com/docs/guides/chat/introduction\n",
    "#write st.write(output) at the end\n",
    "def generate_response(prompt):\n",
    "    response= openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "\n",
    "    ]\n",
    ")\n",
    "    return response['choices'][0]['message']['content']##\n",
    "\n",
    "    if submit_button and user_input:\n",
    "        output= generate_response(user_input)\n",
    "        st.write(output)##\n",
    "\n",
    "#then go to webpage and write Hello and then ask: Write a poem in the style of Shakespeare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now gpt model will not remember any previous conversations. We want layered conversations\n",
    "#test by asking hello,my name is Shubrata. Then if i ask what is my name. Chatbot cant answer\n",
    "#streamlit has so-called session variables session State variables and \n",
    "#it means  these session State variables will basically not be erased every time we interact with the UI they they keep track and do not lose\n",
    "#to initialize the session state  variables\n",
    "if 'messages' not in st.session_state:##\n",
    "    st.session_state['messages'] = [##\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}##\n",
    "    ]##\n",
    "\n",
    "def generate_response(prompt):\n",
    "    st.session_state['messages'].append({\"role\": \"user\", \"content\": prompt})##\n",
    "\n",
    "    completion = openai.ChatCompletion.create(##\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=st.session_state['messages']##\n",
    "    )\n",
    "    response = completion.choices[0].message.content##\n",
    "    st.session_state['messages'].append({\"role\": \"assistant\", \"content\": response})##\n",
    "  \n",
    "    return response##\n",
    "\n",
    "#now go to webpage and ask if it can remember your name\n",
    "#now we have implemented memory into our application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a response container above container\n",
    "response_container=st.container()##\n",
    "container = st.container()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to import message method from the streamlit_chat package \n",
    "from streamlit_chat import message##\n",
    "#that one will give us the option or the the capability to display the messages as if they were in a conversation\n",
    "#show the pictures of emojis and conversation from pdf blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 session state variables \"generated\"&\"past\" are being used to keep track\n",
    "# of the output generated by the application during the current&previous sessions, respectively\n",
    "\n",
    "if \"generated\" not in st.session_state:##\n",
    "    st.session_state[\"generated\"] = []##\n",
    "if \"past\" not in st.session_state:##\n",
    "    st.session_state[\"past\"] = []##\n",
    "\n",
    "def generate_response(prompt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at the very end\n",
    "if st.session_state['generated']: ##\n",
    "    with response_container:##\n",
    "        for i in range(len(st.session_state['generated'])):##\n",
    "            message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user')##\n",
    "            message(st.session_state[\"generated\"][i], key=str(i))##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add    st.session_state['past'].append(prompt)\n",
    "def generate_response(prompt):\n",
    "    st.session_state['messages'].append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.session_state['past'].append(prompt)  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add st.session_state['generated'].append(response)\n",
    "def generate_response(prompt):\n",
    "    st.session_state['messages'].append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.session_state['past'].append(prompt)\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=st.session_state['messages']\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    st.session_state['messages'].append({\"role\": \"assistant\", \"content\": response})\n",
    "    st.session_state['generated'].append(response) ##\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we dont want to write anything. comment st.write(output)\n",
    "if submit_button and user_input:\n",
    "        output= generate_response(user_input)\n",
    "        #st.write(output)##"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
